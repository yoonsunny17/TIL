# Virtural memory :star: 면접빈출 :star:

* steps ini handling a page fault
* 메모리 레퍼런스가 있었는데, 주소 변환하려고 보니 invalid이다
* 그렇다면 페이지가 메모리에 올라와 있지 않다는 것으로 , 트렙이 걸려서 cpu가 운영체제한데 자동으로 넘어가고, ~

* 여기서 사용하는 알고리즘
  * optional algorithm
    * 페이지 폴트를 가장 적게 하는 알고리즘
    * 미래의 참조될 페이지들을 다 안다고 가정한 알고리즘
    * 미래를 다 알고있다는 것을 가정하는 것이므로 실제 사용은 불가능
    * 그랳서 알고리즘 성능에 대한 upper bound를 제공한다 (참고사용 하는 알고리즘)
* 미래를 모르는 상태에서 사용하는 알고리즘
  * LRU
    * 가장 오래전에 넣음
  * LFU
    * 참조 횟수가 가장 적음
    * O(n) 으로 사용하지 않아서 heap으로 만들어서 사용함
* 다양한 캐싱 기법
  * 캐싱 기법
    * 한정된 빠른 공간(=캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식
    * 물리적 메모리로부터 서비스하는 것과 같은 개념 (백킹 스토어 사용)
  * 캐싱기법 예시
    * 캐시 메모리
    * 버퍼 캐시
    * 웹 캐싱
* Paging system의 제약조건
  * 페이징 시스템의 경우 정보가 부족함
  * 페이지 폴트가 났을 때에만 운영체제 자료조작이 가능함
  * clock algorithm
* Page Frame의 Allocation
  * 메모리에서 특정 프로그램이 페이지를 다 장악할 수 있으므로, 이를 방지하기 위해 각각의 프로그램에 페이지를 나누어 주는 것.
  * 방법
    * equal allocation: 모든 프로세스에 똑같은 갯수 할당
      * 어떤 프로그램은 많이 필요로 하고 적게 필요로 하면 비효율
    * proportion allocation: 프로세스 크기에 비례하여 할당
      * 같은 프로그램이어도 시간에 따라 필요 페이지가 다를 수 있음
    * priority allocation: 프로세스의 우선순위에 따라 할당
      * cpu의 우선순위가 높은 프로세스에 준다
  * global replacement
    * replace 시 다른 process에 할당된 frame을 빼앗아 올 수 있다.
    * FIFO, LRU, LFU 등의 알고리즘을 사용하면 프로세스별로 그때그때 할당량이 조절된다. (그래서 미리 할당하지 않는 방법)
    * working set, PFF 알고리즘...
  * thrashing
  * thrashing diagram
    * 뚝 떨어지는 지점이 thrashing이 발생하는 경우
  * working-set model
    * working-set algorithm
      * 워킹셋을 우리가 미리 알 수 없다. 과거를 통해 워킹셋을 주장한다.
      * 워킹셋이 보장되지 않으면 swap out, 보장되면 메모리에 올려줌
  * PFF(Page-Fault Frequency)
  * Page Size의 결정
    * page size가 너무 작으면, page table이 너무 커져야 함(낭비)
    * 메모리 크기가 커지면, 그에 따라 페이지 사이즈도 키워줘야 함
    * 페이지 사이즈 줄이면 (페이지 사이즈의 파급효과)
      * 똑같은 크기의 메모리에서 더 잘게 썰어내는 것이라서 페이지 수 증가
      * 페이지 테이블 크기 증가 (낭비)
      * 하지만 페이지 내에서 사용이 안되는 부분이 줄어든다
      * 꼭 필요한 정보만 메모리에 올라오게 되어 메모리 이용이 효율적일 수 있다.
      * locality